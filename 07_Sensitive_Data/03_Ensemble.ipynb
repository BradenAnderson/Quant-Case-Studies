{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6133db7-b3cc-40da-a6c4-e0822768e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitive_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df90d11-4fc3-49a8-b253-9efe385ee4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x41</th>\n",
       "      <th>x42</th>\n",
       "      <th>x43</th>\n",
       "      <th>x44</th>\n",
       "      <th>x45</th>\n",
       "      <th>x46</th>\n",
       "      <th>x47</th>\n",
       "      <th>x48</th>\n",
       "      <th>x49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166563</td>\n",
       "      <td>-3.961588</td>\n",
       "      <td>4.621113</td>\n",
       "      <td>2.481908</td>\n",
       "      <td>-1.800135</td>\n",
       "      <td>0.804684</td>\n",
       "      <td>6.718751</td>\n",
       "      <td>-14.789997</td>\n",
       "      <td>-1.040673</td>\n",
       "      <td>-4.204950</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.497117</td>\n",
       "      <td>5.414063</td>\n",
       "      <td>-2.325655</td>\n",
       "      <td>1.674827</td>\n",
       "      <td>-0.264332</td>\n",
       "      <td>60.781427</td>\n",
       "      <td>-7.689696</td>\n",
       "      <td>0.151589</td>\n",
       "      <td>-8.040166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.149894</td>\n",
       "      <td>-0.585676</td>\n",
       "      <td>27.839856</td>\n",
       "      <td>4.152333</td>\n",
       "      <td>6.426802</td>\n",
       "      <td>-2.426943</td>\n",
       "      <td>40.477058</td>\n",
       "      <td>-6.725709</td>\n",
       "      <td>0.896421</td>\n",
       "      <td>0.330165</td>\n",
       "      <td>...</td>\n",
       "      <td>36.292790</td>\n",
       "      <td>4.490915</td>\n",
       "      <td>0.762561</td>\n",
       "      <td>6.526662</td>\n",
       "      <td>1.007927</td>\n",
       "      <td>15.805696</td>\n",
       "      <td>-4.896678</td>\n",
       "      <td>-0.320283</td>\n",
       "      <td>16.719974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1         x2        x3        x4        x5         x6  \\\n",
       "0 -0.166563 -3.961588   4.621113  2.481908 -1.800135  0.804684   6.718751   \n",
       "1 -0.149894 -0.585676  27.839856  4.152333  6.426802 -2.426943  40.477058   \n",
       "\n",
       "          x7        x8        x9  ...        x41       x42       x43  \\\n",
       "0 -14.789997 -1.040673 -4.204950  ...  -1.497117  5.414063 -2.325655   \n",
       "1  -6.725709  0.896421  0.330165  ...  36.292790  4.490915  0.762561   \n",
       "\n",
       "        x44       x45        x46       x47       x48        x49  y  \n",
       "0  1.674827 -0.264332  60.781427 -7.689696  0.151589  -8.040166  0  \n",
       "1  6.526662  1.007927  15.805696 -4.896678 -0.320283  16.719974  0  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./CS7_preprocessed.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63479d1f-7282-49f6-b3e5-cba5fcd7bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160000 entries, 0 to 159999\n",
      "Data columns (total 51 columns):\n",
      " #   Column  Non-Null Count   Dtype   \n",
      "---  ------  --------------   -----   \n",
      " 0   x0      159974 non-null  float64 \n",
      " 1   x1      159975 non-null  float64 \n",
      " 2   x2      159962 non-null  float64 \n",
      " 3   x3      159963 non-null  float64 \n",
      " 4   x4      159974 non-null  float64 \n",
      " 5   x5      159963 non-null  float64 \n",
      " 6   x6      159974 non-null  float64 \n",
      " 7   x7      159973 non-null  float64 \n",
      " 8   x8      159979 non-null  float64 \n",
      " 9   x9      159970 non-null  float64 \n",
      " 10  x10     159957 non-null  float64 \n",
      " 11  x11     159970 non-null  float64 \n",
      " 12  x12     159964 non-null  float64 \n",
      " 13  x13     159969 non-null  float64 \n",
      " 14  x14     159966 non-null  float64 \n",
      " 15  x15     159965 non-null  float64 \n",
      " 16  x16     159974 non-null  float64 \n",
      " 17  x17     159973 non-null  float64 \n",
      " 18  x18     159960 non-null  float64 \n",
      " 19  x19     159965 non-null  float64 \n",
      " 20  x20     159962 non-null  float64 \n",
      " 21  x21     159971 non-null  float64 \n",
      " 22  x22     159973 non-null  float64 \n",
      " 23  x23     159953 non-null  float64 \n",
      " 24  x24     159972 non-null  category\n",
      " 25  x25     159978 non-null  float64 \n",
      " 26  x26     159964 non-null  float64 \n",
      " 27  x27     159970 non-null  float64 \n",
      " 28  x28     159965 non-null  float64 \n",
      " 29  x29     159970 non-null  category\n",
      " 30  x30     159970 non-null  category\n",
      " 31  x31     159961 non-null  float64 \n",
      " 32  x32     159969 non-null  float64 \n",
      " 33  x33     159959 non-null  float64 \n",
      " 34  x34     159959 non-null  float64 \n",
      " 35  x35     159970 non-null  float64 \n",
      " 36  x36     159973 non-null  float64 \n",
      " 37  x37     159977 non-null  float64 \n",
      " 38  x38     159969 non-null  float64 \n",
      " 39  x39     159977 non-null  float64 \n",
      " 40  x40     159964 non-null  float64 \n",
      " 41  x41     159960 non-null  float64 \n",
      " 42  x42     159974 non-null  float64 \n",
      " 43  x43     159963 non-null  float64 \n",
      " 44  x44     159960 non-null  float64 \n",
      " 45  x45     159971 non-null  float64 \n",
      " 46  x46     159969 non-null  float64 \n",
      " 47  x47     159963 non-null  float64 \n",
      " 48  x48     159968 non-null  float64 \n",
      " 49  x49     159968 non-null  float64 \n",
      " 50  y       160000 non-null  int64   \n",
      "dtypes: category(3), float64(47), int64(1)\n",
      "memory usage: 59.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = convert_strings_to_category(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dfd3cd-f541-4673-a455-62ff9b001693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (128000, 51)\n",
      "Val Shape: (16000, 51)\n",
      "Test Shape: (16000, 51)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = create_train_val_test_sets(df=df, \n",
    "                                                       target_column=\"y\", \n",
    "                                                       test_size=0.1, \n",
    "                                                       val_size=0.1, \n",
    "                                                       random_state=7742)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8bab53-6c44-4c09-bc75-e300a68e69b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAI Train Shape: (128000, 17)\n",
      "DAI Val Shape: (16000, 17)\n",
      "DAI Test Shape: (16000, 17)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=\"y\")\n",
    "y_train = train_df.loc[:,\"y\"].to_numpy()\n",
    "\n",
    "X_val = val_df.drop(columns=\"y\")\n",
    "y_val = val_df.loc[:,\"y\"].to_numpy()\n",
    "\n",
    "X_test = test_df.drop(columns=\"y\")\n",
    "y_test = test_df.loc[:,\"y\"].to_numpy()\n",
    "\n",
    "# Subset to features selected by DAI\n",
    "X_train_dai, X_val_dai, X_test_dai = subset_to_dai_selected_features(X_train=X_train, \n",
    "                                                                     X_val=X_val, \n",
    "                                                                     X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9349e1-f843-447f-a418-c0cbf1a011ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers_dict = {\"accuracy\":make_scorer(accuracy_score), \n",
    "                \"f025_score\":make_scorer(fbeta_score, beta=0.25),\n",
    "                \"f05_score\":make_scorer(fbeta_score, beta=0.5), \n",
    "                \"avg_dollars_lost_per_prediction\":make_scorer(score_func=average_dollars_scorer_sklearn, \n",
    "                                                              greater_is_better=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d648218-0033-469f-b0cc-04541af168fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lgbm = {\"boosting_type\":\"gbdt\",\n",
    "               \"colsample_bytree\":0.8,\n",
    "               \"bagging_seed\":7742,\n",
    "               \"feature_fraction_seed\":7743,\n",
    "               \"importance_type\":\"gain\",\n",
    "               \"learning_rate\":0.05,\n",
    "               \"max_bin\":63,\n",
    "               \"max_delta_step\":0.0,\n",
    "               \"max_depth\":10,\n",
    "               \"num_leaves\":1024,\n",
    "               \"min_child_samples\":20,\n",
    "               \"min_child_weight\":0.001,\n",
    "               \"min_data_in_bin\":1,\n",
    "               \"min_split_gain\":0.0,\n",
    "               \"n_estimators\":715,\n",
    "               \"objective\":\"binary\",\n",
    "               \"reg_alpha\":0.0,\n",
    "               \"reg_lambda\":0.0,\n",
    "               \"scale_pos_weight\":1.0,\n",
    "               \"seed\":534401655,\n",
    "               \"subsample\":0.7,\n",
    "               \"subsample_freq\":1}\n",
    "\n",
    "best_param_grid = {key:[value] for key, value in best_params_lgbm.items()}\n",
    "best_param_grid_imp = {f\"model__{key}\":value for key, value in best_param_grid.items()}\n",
    "best_param_grid_imp['impute__strategy'] = [\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816f4afd-0a4d-4dd5-be5c-0e53641f2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = StratifiedKFold(n_splits=5, \n",
    "                              shuffle=True, \n",
    "                              random_state=7742)\n",
    "\n",
    "\n",
    "train_dai_df = pd.DataFrame(X_train_dai)\n",
    "train_dai_df['y'] = y_train\n",
    "\n",
    "train_dai_df.reset_index(drop=True, inplace=True)\n",
    "X_train_dai = train_dai_df.drop(columns=\"y\")\n",
    "y_train = train_dai_df.loc[:, \"y\"]\n",
    "folds = {}\n",
    "\n",
    "for index, (train_ind, test_ind) in enumerate(cv_splitter.split(train_dai_df.drop(columns=\"y\"), \n",
    "                                                                train_dai_df.loc[:,\"y\"].to_numpy()), start=1):\n",
    "    \n",
    "    folds[f'fold{index}'] = {f\"train_ind\":train_ind, f\"test_ind\":test_ind}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993c8584-72f4-4cf9-9300-65aedaf585a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_pipe = Pipeline(steps=[(\"impute\", SimpleImputer()), \n",
    "                                  ('model', LGBMClassifier(n_jobs=32, random_state=7742))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a0116b-51b8-4166-a512-9f0a8a34febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_and_ind = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8eecc9d-27bd-4829-9857-978c29bed646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      7,      8, ..., 127987, 127990, 127995])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds[\"fold1\"]['test_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae2347-defe-45c0-b721-8d90e441a94b",
   "metadata": {},
   "source": [
    "## Fold 1 Probabilities from LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d931275-886e-4026-957b-6fe8a3e985ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's binary_logloss: 0.131056\tvalid_0's avg_dollars_lost_per_prediction: 2.5375\tvalid_0's f05_score: 0.946659\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "model1 = fit_lgbm(X_train=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold1\"][\"train_ind\"])], \n",
    "                  y_train=y_train[folds[\"fold1\"][\"train_ind\"]].to_numpy(), \n",
    "                  X_val=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold1\"][\"test_ind\"])], \n",
    "                  y_val=y_train[folds[\"fold1\"][\"test_ind\"]].to_numpy(),\n",
    "                  model_pipe=lgbm_model_pipe, \n",
    "                  lgbm_param_grid=best_param_grid_imp, \n",
    "                  cv=2)\n",
    "\n",
    "folds[\"fold1\"][\"preds\"] = model1.predict_proba(X_train_dai.loc[X_train_dai.index.isin(folds[\"fold1\"][\"test_ind\"])])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce630c78-af72-4383-b6fa-d8a2ea45e436",
   "metadata": {},
   "source": [
    "## Fold 2 Probabilities from LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "818eaf75-4548-4dfa-a54c-e85c6ea8b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[416]\tvalid_0's binary_logloss: 0.134026\tvalid_0's avg_dollars_lost_per_prediction: 2.57656\tvalid_0's f05_score: 0.945145\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "model2 = fit_lgbm(X_train=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold2\"][\"train_ind\"])], \n",
    "                  y_train=y_train[folds[\"fold2\"][\"train_ind\"]].to_numpy(),\n",
    "                  X_val=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold2\"][\"test_ind\"])], \n",
    "                  y_val=y_train[folds[\"fold2\"][\"test_ind\"]].to_numpy(),\n",
    "                  model_pipe=lgbm_model_pipe, \n",
    "                  lgbm_param_grid=best_param_grid_imp, \n",
    "                  cv=2)\n",
    "\n",
    "folds[\"fold2\"][\"preds\"] = model2.predict_proba(X_train_dai.loc[X_train_dai.index.isin(folds[\"fold2\"][\"test_ind\"])])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f18c6-1422-49ba-886f-8d90e9cf37c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437198eb-939c-453d-878d-b485390b8a4f",
   "metadata": {},
   "source": [
    "## Fold 3 Probabilities from LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35ff9708-63f4-4e7c-bd2c-aaea09a91bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[423]\tvalid_0's binary_logloss: 0.135549\tvalid_0's avg_dollars_lost_per_prediction: 2.61094\tvalid_0's f05_score: 0.944916\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "model3 = fit_lgbm(X_train=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold3\"][\"train_ind\"])], \n",
    "                  y_train=y_train[folds[\"fold3\"][\"train_ind\"]].to_numpy(), \n",
    "                  X_val=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold3\"][\"test_ind\"])], \n",
    "                  y_val=y_train[folds[\"fold3\"][\"test_ind\"]].to_numpy(),\n",
    "                  model_pipe=lgbm_model_pipe, \n",
    "                  lgbm_param_grid=best_param_grid_imp, \n",
    "                  cv=2)\n",
    "\n",
    "folds[\"fold3\"][\"preds\"] = model3.predict_proba(X_train_dai.loc[X_train_dai.index.isin(folds[\"fold3\"][\"test_ind\"])])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681cabd-ffae-4c5f-88a7-1d9cc87ca868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8515fd43-2533-4836-87d8-fe39ff1bd339",
   "metadata": {},
   "source": [
    "## Fold 4 Probabilities from LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d604a320-4209-4651-a6c8-45b25df93ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.127151\tvalid_0's avg_dollars_lost_per_prediction: 2.46563\tvalid_0's f05_score: 0.947828\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "model4 = fit_lgbm(X_train=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold4\"][\"train_ind\"])], \n",
    "                  y_train=y_train[folds[\"fold4\"][\"train_ind\"]].to_numpy(), \n",
    "                  X_val=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold4\"][\"test_ind\"])], \n",
    "                  y_val=y_train[folds[\"fold4\"][\"test_ind\"]].to_numpy(),\n",
    "                  model_pipe=lgbm_model_pipe, \n",
    "                  lgbm_param_grid=best_param_grid_imp, \n",
    "                  cv=2)\n",
    "\n",
    "folds[\"fold4\"][\"preds\"] = model4.predict_proba(X_train_dai.loc[X_train_dai.index.isin(folds[\"fold4\"][\"test_ind\"])])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca90431-df2f-470f-9969-b34c41f326e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4886e366-fa94-482c-9293-c92f332a54cc",
   "metadata": {},
   "source": [
    "## Fold 5 Probabilities from LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a548be82-3669-4397-9b14-196a840d1af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's binary_logloss: 0.129679\tvalid_0's avg_dollars_lost_per_prediction: 2.58516\tvalid_0's f05_score: 0.945569\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "model5 = fit_lgbm(X_train=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold5\"][\"train_ind\"])], \n",
    "                  y_train=y_train[folds[\"fold5\"][\"train_ind\"]].to_numpy(), \n",
    "                  X_val=X_train_dai.loc[X_train_dai.index.isin(folds[\"fold5\"][\"test_ind\"])], \n",
    "                  y_val=y_train[folds[\"fold5\"][\"test_ind\"]].to_numpy(),\n",
    "                  model_pipe=lgbm_model_pipe, \n",
    "                  lgbm_param_grid=best_param_grid_imp, \n",
    "                  cv=2)\n",
    "\n",
    "folds[\"fold5\"][\"preds\"] = model5.predict_proba(X_train_dai.loc[X_train_dai.index.isin(folds[\"fold5\"][\"test_ind\"])])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985612bc-4122-4394-a0b4-354a179fa10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x48</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x20</th>\n",
       "      <th>x28</th>\n",
       "      <th>x46</th>\n",
       "      <th>x49</th>\n",
       "      <th>x37</th>\n",
       "      <th>x42</th>\n",
       "      <th>x12</th>\n",
       "      <th>x32</th>\n",
       "      <th>x7</th>\n",
       "      <th>x2</th>\n",
       "      <th>x38</th>\n",
       "      <th>x41</th>\n",
       "      <th>x6</th>\n",
       "      <th>x40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.818280</td>\n",
       "      <td>-4.676670</td>\n",
       "      <td>10.352920</td>\n",
       "      <td>2.029764</td>\n",
       "      <td>-30.102992</td>\n",
       "      <td>32.780607</td>\n",
       "      <td>-14.191745</td>\n",
       "      <td>-72.62</td>\n",
       "      <td>0.582534</td>\n",
       "      <td>-10.735783</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-15.072493</td>\n",
       "      <td>0.419611</td>\n",
       "      <td>-24.254114</td>\n",
       "      <td>-26.823132</td>\n",
       "      <td>0.610082</td>\n",
       "      <td>3.604330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.102613</td>\n",
       "      <td>1.519396</td>\n",
       "      <td>-12.122562</td>\n",
       "      <td>-4.198570</td>\n",
       "      <td>-16.416524</td>\n",
       "      <td>55.582887</td>\n",
       "      <td>34.763313</td>\n",
       "      <td>1918.51</td>\n",
       "      <td>6.188595</td>\n",
       "      <td>9.566781</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.656567</td>\n",
       "      <td>-0.427442</td>\n",
       "      <td>23.569760</td>\n",
       "      <td>26.066290</td>\n",
       "      <td>-0.621469</td>\n",
       "      <td>-20.189674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x48       x23        x27       x20        x28        x46        x49  \\\n",
       "0 -4.818280 -4.676670  10.352920  2.029764 -30.102992  32.780607 -14.191745   \n",
       "1  3.102613  1.519396 -12.122562 -4.198570 -16.416524  55.582887  34.763313   \n",
       "\n",
       "       x37       x42        x12   x32         x7        x2        x38  \\\n",
       "0   -72.62  0.582534 -10.735783  0.01 -15.072493  0.419611 -24.254114   \n",
       "1  1918.51  6.188595   9.566781  0.00   2.656567 -0.427442  23.569760   \n",
       "\n",
       "         x41        x6        x40  \n",
       "0 -26.823132  0.610082   3.604330  \n",
       "1  26.066290 -0.621469 -20.189674  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dai.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b1a6183-6696-4aab-80f4-92c99096de9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x48</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x20</th>\n",
       "      <th>x28</th>\n",
       "      <th>x46</th>\n",
       "      <th>x49</th>\n",
       "      <th>x37</th>\n",
       "      <th>x42</th>\n",
       "      <th>x12</th>\n",
       "      <th>x32</th>\n",
       "      <th>x7</th>\n",
       "      <th>x2</th>\n",
       "      <th>x38</th>\n",
       "      <th>x41</th>\n",
       "      <th>x6</th>\n",
       "      <th>x40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>-0.135665</td>\n",
       "      <td>-29.003454</td>\n",
       "      <td>-7.159328</td>\n",
       "      <td>-2.123370</td>\n",
       "      <td>-13.897687</td>\n",
       "      <td>77.038840</td>\n",
       "      <td>28.650379</td>\n",
       "      <td>1438.24</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>24.098276</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-12.003051</td>\n",
       "      <td>-7.447920</td>\n",
       "      <td>10.262458</td>\n",
       "      <td>11.349467</td>\n",
       "      <td>-10.828716</td>\n",
       "      <td>-8.089228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54081</th>\n",
       "      <td>-0.133721</td>\n",
       "      <td>-4.830448</td>\n",
       "      <td>15.588912</td>\n",
       "      <td>8.475162</td>\n",
       "      <td>4.911999</td>\n",
       "      <td>-52.428648</td>\n",
       "      <td>-17.259751</td>\n",
       "      <td>-1267.47</td>\n",
       "      <td>-6.739039</td>\n",
       "      <td>6.327413</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.395886</td>\n",
       "      <td>-10.351719</td>\n",
       "      <td>32.510607</td>\n",
       "      <td>35.954160</td>\n",
       "      <td>-15.050622</td>\n",
       "      <td>-5.562226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x48        x23        x27       x20        x28        x46  \\\n",
       "153151 -0.135665 -29.003454  -7.159328 -2.123370 -13.897687  77.038840   \n",
       "54081  -0.133721  -4.830448  15.588912  8.475162   4.911999 -52.428648   \n",
       "\n",
       "              x49      x37       x42        x12   x32         x7         x2  \\\n",
       "153151  28.650379  1438.24  0.964448  24.098276 -0.01 -12.003051  -7.447920   \n",
       "54081  -17.259751 -1267.47 -6.739039   6.327413  0.00 -73.395886 -10.351719   \n",
       "\n",
       "              x38        x41         x6       x40  \n",
       "153151  10.262458  11.349467 -10.828716 -8.089228  \n",
       "54081   32.510607  35.954160 -15.050622 -5.562226  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_dai.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c1901b-b93e-4015-befc-d18a695ba5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x48</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x20</th>\n",
       "      <th>x28</th>\n",
       "      <th>x46</th>\n",
       "      <th>x49</th>\n",
       "      <th>x37</th>\n",
       "      <th>x42</th>\n",
       "      <th>x12</th>\n",
       "      <th>x32</th>\n",
       "      <th>x7</th>\n",
       "      <th>x2</th>\n",
       "      <th>x38</th>\n",
       "      <th>x41</th>\n",
       "      <th>x6</th>\n",
       "      <th>x40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156290</th>\n",
       "      <td>-2.532465</td>\n",
       "      <td>-11.966421</td>\n",
       "      <td>3.949634</td>\n",
       "      <td>10.180605</td>\n",
       "      <td>22.751143</td>\n",
       "      <td>-66.780025</td>\n",
       "      <td>6.334020</td>\n",
       "      <td>-1914.85</td>\n",
       "      <td>7.246131</td>\n",
       "      <td>-37.403131</td>\n",
       "      <td>0.01</td>\n",
       "      <td>44.035923</td>\n",
       "      <td>-1.683509</td>\n",
       "      <td>-0.078549</td>\n",
       "      <td>-0.086869</td>\n",
       "      <td>-2.447696</td>\n",
       "      <td>7.042585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136803</th>\n",
       "      <td>0.108401</td>\n",
       "      <td>4.179954</td>\n",
       "      <td>7.095808</td>\n",
       "      <td>13.903758</td>\n",
       "      <td>21.540864</td>\n",
       "      <td>-57.086176</td>\n",
       "      <td>-3.084239</td>\n",
       "      <td>-1713.34</td>\n",
       "      <td>2.910421</td>\n",
       "      <td>-10.437425</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-10.607838</td>\n",
       "      <td>-5.937418</td>\n",
       "      <td>10.922252</td>\n",
       "      <td>12.079147</td>\n",
       "      <td>-8.632560</td>\n",
       "      <td>-10.316435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x48        x23       x27        x20        x28        x46  \\\n",
       "156290 -2.532465 -11.966421  3.949634  10.180605  22.751143 -66.780025   \n",
       "136803  0.108401   4.179954  7.095808  13.903758  21.540864 -57.086176   \n",
       "\n",
       "             x49      x37       x42        x12   x32         x7        x2  \\\n",
       "156290  6.334020 -1914.85  7.246131 -37.403131  0.01  44.035923 -1.683509   \n",
       "136803 -3.084239 -1713.34  2.910421 -10.437425 -0.00 -10.607838 -5.937418   \n",
       "\n",
       "              x38        x41        x6        x40  \n",
       "156290  -0.078549  -0.086869 -2.447696   7.042585  \n",
       "136803  10.922252  12.079147 -8.632560 -10.316435  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dai.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d157f-979e-4e61-a0f5-8836e3bb4621",
   "metadata": {},
   "source": [
    "## Validation and Test Set LGBM Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "135a13c4-a8f6-4802-ac48-b1890355cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] seed is set=534401655, random_state=7742 will be ignored. Current value: seed=534401655\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[450]\tvalid_0's binary_logloss: 0.132653\tvalid_0's avg_dollars_lost_per_prediction: 2.4725\tvalid_0's f05_score: 0.947468\n",
      "Evaluated only: binary_logloss\n"
     ]
    }
   ],
   "source": [
    "final_model = fit_lgbm(X_train=X_train_dai, \n",
    "                       y_train=y_train, \n",
    "                       X_val=X_val_dai, \n",
    "                       y_val=y_val,\n",
    "                       model_pipe=lgbm_model_pipe, \n",
    "                       lgbm_param_grid=best_param_grid_imp, \n",
    "                       cv=2)\n",
    "\n",
    "val_preds = final_model.predict_proba(X_val_dai)[:,1]\n",
    "X_val_ensemble = X_val_dai.copy(deep=True)\n",
    "X_val_ensemble['lgbm_probs'] = val_preds\n",
    "\n",
    "\n",
    "test_preds = final_model.predict_proba(X_test_dai)[:,1]\n",
    "X_test_ensemble = X_test_dai.copy()\n",
    "X_test_ensemble[\"lgbm_probs\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b4d28e-fa67-4680-97dc-79bbc48a4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds_and_preds = sorted([(i, p) for i, p in zip([ind for fold in folds.values() for ind in fold['test_ind']], \n",
    "                                            [pred for fold in folds.values() for pred in fold['preds']])], key=lambda sublist: sublist[0])\n",
    "train_inds = [i for i, p in train_inds_and_preds]\n",
    "train_preds = [p for i, p in train_inds_and_preds]\n",
    "\n",
    "X_train_ensemble = X_train_dai.copy()\n",
    "X_train_ensemble[\"lgbm_probs\"] = train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3718a-eaf4-4b95-80a4-2fcf549afb0c",
   "metadata": {},
   "source": [
    "## Fit MLP using LGBM Probs as a features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b050cf1e-59b0-40de-846c-e69e774be3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "              hidden_layer_sizes=(300, 200, 100), learning_rate_init=0.01,\n",
       "              max_iter=20000, random_state=7742, warm_start=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                ('model',\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pipe = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"mean\")),\n",
    "                           (\"model\", MLPClassifier(random_state=7742,\n",
    "                                                   verbose=False,\n",
    "                                                   warm_start=True,\n",
    "                                                   early_stopping=True,\n",
    "                                                   max_iter=20_000, \n",
    "                                                   alpha=1e-5, \n",
    "                                                   hidden_layer_sizes=(300,200,100), \n",
    "                                                   learning_rate_init=0.01))])\n",
    "\n",
    "mlp_pipe.fit(X_train_ensemble, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d1a8c6-e794-4154-9b77-4bfb34244279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x48</th>\n",
       "      <th>x23</th>\n",
       "      <th>x27</th>\n",
       "      <th>x20</th>\n",
       "      <th>x28</th>\n",
       "      <th>x46</th>\n",
       "      <th>x49</th>\n",
       "      <th>x37</th>\n",
       "      <th>x42</th>\n",
       "      <th>x12</th>\n",
       "      <th>x32</th>\n",
       "      <th>x7</th>\n",
       "      <th>x2</th>\n",
       "      <th>x38</th>\n",
       "      <th>x41</th>\n",
       "      <th>x6</th>\n",
       "      <th>x40</th>\n",
       "      <th>lgbm_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>-0.135665</td>\n",
       "      <td>-29.003454</td>\n",
       "      <td>-7.159328</td>\n",
       "      <td>-2.123370</td>\n",
       "      <td>-13.897687</td>\n",
       "      <td>77.038840</td>\n",
       "      <td>28.650379</td>\n",
       "      <td>1438.24</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>24.098276</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-12.003051</td>\n",
       "      <td>-7.447920</td>\n",
       "      <td>10.262458</td>\n",
       "      <td>11.349467</td>\n",
       "      <td>-10.828716</td>\n",
       "      <td>-8.089228</td>\n",
       "      <td>0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54081</th>\n",
       "      <td>-0.133721</td>\n",
       "      <td>-4.830448</td>\n",
       "      <td>15.588912</td>\n",
       "      <td>8.475162</td>\n",
       "      <td>4.911999</td>\n",
       "      <td>-52.428648</td>\n",
       "      <td>-17.259751</td>\n",
       "      <td>-1267.47</td>\n",
       "      <td>-6.739039</td>\n",
       "      <td>6.327413</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-73.395886</td>\n",
       "      <td>-10.351719</td>\n",
       "      <td>32.510607</td>\n",
       "      <td>35.954160</td>\n",
       "      <td>-15.050622</td>\n",
       "      <td>-5.562226</td>\n",
       "      <td>0.999169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16600</th>\n",
       "      <td>2.097463</td>\n",
       "      <td>5.899921</td>\n",
       "      <td>0.172830</td>\n",
       "      <td>-2.465437</td>\n",
       "      <td>-12.928949</td>\n",
       "      <td>-32.265216</td>\n",
       "      <td>-10.913424</td>\n",
       "      <td>553.27</td>\n",
       "      <td>1.851259</td>\n",
       "      <td>-18.125503</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13.303811</td>\n",
       "      <td>7.581987</td>\n",
       "      <td>7.749179</td>\n",
       "      <td>8.569979</td>\n",
       "      <td>11.023639</td>\n",
       "      <td>10.758549</td>\n",
       "      <td>0.007594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54009</th>\n",
       "      <td>-1.276345</td>\n",
       "      <td>11.346091</td>\n",
       "      <td>-1.803787</td>\n",
       "      <td>4.811472</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>-22.999224</td>\n",
       "      <td>-5.638077</td>\n",
       "      <td>350.60</td>\n",
       "      <td>-5.166516</td>\n",
       "      <td>5.728755</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-44.183957</td>\n",
       "      <td>5.340435</td>\n",
       "      <td>23.432755</td>\n",
       "      <td>25.914774</td>\n",
       "      <td>7.764592</td>\n",
       "      <td>-25.711235</td>\n",
       "      <td>0.007352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40254</th>\n",
       "      <td>-2.327353</td>\n",
       "      <td>-3.466436</td>\n",
       "      <td>-1.026047</td>\n",
       "      <td>-3.795519</td>\n",
       "      <td>6.836663</td>\n",
       "      <td>-37.926008</td>\n",
       "      <td>6.590798</td>\n",
       "      <td>976.14</td>\n",
       "      <td>-3.194539</td>\n",
       "      <td>-29.836625</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-8.369497</td>\n",
       "      <td>20.411155</td>\n",
       "      <td>34.504885</td>\n",
       "      <td>38.159674</td>\n",
       "      <td>29.676286</td>\n",
       "      <td>4.573880</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148571</th>\n",
       "      <td>0.424333</td>\n",
       "      <td>4.823892</td>\n",
       "      <td>-1.424600</td>\n",
       "      <td>5.769466</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>-41.068522</td>\n",
       "      <td>6.130660</td>\n",
       "      <td>-659.39</td>\n",
       "      <td>-4.117836</td>\n",
       "      <td>-9.711528</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-18.526169</td>\n",
       "      <td>-8.615393</td>\n",
       "      <td>12.806808</td>\n",
       "      <td>14.163317</td>\n",
       "      <td>-12.526134</td>\n",
       "      <td>-13.548645</td>\n",
       "      <td>0.869132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110072</th>\n",
       "      <td>2.438535</td>\n",
       "      <td>16.479998</td>\n",
       "      <td>-10.948547</td>\n",
       "      <td>-6.490398</td>\n",
       "      <td>-5.265917</td>\n",
       "      <td>33.477369</td>\n",
       "      <td>23.732092</td>\n",
       "      <td>370.74</td>\n",
       "      <td>1.317636</td>\n",
       "      <td>6.847680</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27.038077</td>\n",
       "      <td>-11.609289</td>\n",
       "      <td>-15.299206</td>\n",
       "      <td>-16.919711</td>\n",
       "      <td>-16.879034</td>\n",
       "      <td>-10.988400</td>\n",
       "      <td>0.017823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46289</th>\n",
       "      <td>-4.075310</td>\n",
       "      <td>-29.923342</td>\n",
       "      <td>-5.067366</td>\n",
       "      <td>-5.965834</td>\n",
       "      <td>-1.562378</td>\n",
       "      <td>-58.700981</td>\n",
       "      <td>-32.546766</td>\n",
       "      <td>329.99</td>\n",
       "      <td>-7.287499</td>\n",
       "      <td>-23.681613</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51.371452</td>\n",
       "      <td>16.875481</td>\n",
       "      <td>-20.724607</td>\n",
       "      <td>-22.919777</td>\n",
       "      <td>24.535682</td>\n",
       "      <td>38.568265</td>\n",
       "      <td>0.822426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>-2.681908</td>\n",
       "      <td>-5.122926</td>\n",
       "      <td>1.891111</td>\n",
       "      <td>3.735759</td>\n",
       "      <td>-1.342772</td>\n",
       "      <td>84.641920</td>\n",
       "      <td>17.160410</td>\n",
       "      <td>-596.00</td>\n",
       "      <td>-4.219387</td>\n",
       "      <td>45.799598</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-47.803456</td>\n",
       "      <td>-25.622991</td>\n",
       "      <td>-18.427550</td>\n",
       "      <td>-20.379413</td>\n",
       "      <td>-37.253903</td>\n",
       "      <td>-28.351833</td>\n",
       "      <td>0.002023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128354</th>\n",
       "      <td>-2.553839</td>\n",
       "      <td>-14.233863</td>\n",
       "      <td>14.762842</td>\n",
       "      <td>2.619065</td>\n",
       "      <td>16.901680</td>\n",
       "      <td>-8.062960</td>\n",
       "      <td>-49.895010</td>\n",
       "      <td>480.16</td>\n",
       "      <td>6.223992</td>\n",
       "      <td>19.282506</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-11.369102</td>\n",
       "      <td>26.007148</td>\n",
       "      <td>9.831254</td>\n",
       "      <td>10.872589</td>\n",
       "      <td>37.812440</td>\n",
       "      <td>18.337899</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x48        x23        x27       x20        x28        x46  \\\n",
       "153151 -0.135665 -29.003454  -7.159328 -2.123370 -13.897687  77.038840   \n",
       "54081  -0.133721  -4.830448  15.588912  8.475162   4.911999 -52.428648   \n",
       "16600   2.097463   5.899921   0.172830 -2.465437 -12.928949 -32.265216   \n",
       "54009  -1.276345  11.346091  -1.803787  4.811472   0.621300 -22.999224   \n",
       "40254  -2.327353  -3.466436  -1.026047 -3.795519   6.836663 -37.926008   \n",
       "...          ...        ...        ...       ...        ...        ...   \n",
       "148571  0.424333   4.823892  -1.424600  5.769466   0.026230 -41.068522   \n",
       "110072  2.438535  16.479998 -10.948547 -6.490398  -5.265917  33.477369   \n",
       "46289  -4.075310 -29.923342  -5.067366 -5.965834  -1.562378 -58.700981   \n",
       "4559   -2.681908  -5.122926   1.891111  3.735759  -1.342772  84.641920   \n",
       "128354 -2.553839 -14.233863  14.762842  2.619065  16.901680  -8.062960   \n",
       "\n",
       "              x49      x37       x42        x12   x32         x7         x2  \\\n",
       "153151  28.650379  1438.24  0.964448  24.098276 -0.01 -12.003051  -7.447920   \n",
       "54081  -17.259751 -1267.47 -6.739039   6.327413  0.00 -73.395886 -10.351719   \n",
       "16600  -10.913424   553.27  1.851259 -18.125503  0.01  13.303811   7.581987   \n",
       "54009   -5.638077   350.60 -5.166516   5.728755 -0.01 -44.183957   5.340435   \n",
       "40254    6.590798   976.14 -3.194539 -29.836625 -0.01  -8.369497  20.411155   \n",
       "...           ...      ...       ...        ...   ...        ...        ...   \n",
       "148571   6.130660  -659.39 -4.117836  -9.711528  0.00 -18.526169  -8.615393   \n",
       "110072  23.732092   370.74  1.317636   6.847680  0.01  27.038077 -11.609289   \n",
       "46289  -32.546766   329.99 -7.287499 -23.681613  0.00  51.371452  16.875481   \n",
       "4559    17.160410  -596.00 -4.219387  45.799598 -0.01 -47.803456 -25.622991   \n",
       "128354 -49.895010   480.16  6.223992  19.282506 -0.01 -11.369102  26.007148   \n",
       "\n",
       "              x38        x41         x6        x40  lgbm_probs  \n",
       "153151  10.262458  11.349467 -10.828716  -8.089228    0.002125  \n",
       "54081   32.510607  35.954160 -15.050622  -5.562226    0.999169  \n",
       "16600    7.749179   8.569979  11.023639  10.758549    0.007594  \n",
       "54009   23.432755  25.914774   7.764592 -25.711235    0.007352  \n",
       "40254   34.504885  38.159674  29.676286   4.573880    0.001125  \n",
       "...           ...        ...        ...        ...         ...  \n",
       "148571  12.806808  14.163317 -12.526134 -13.548645    0.869132  \n",
       "110072 -15.299206 -16.919711 -16.879034 -10.988400    0.017823  \n",
       "46289  -20.724607 -22.919777  24.535682  38.568265    0.822426  \n",
       "4559   -18.427550 -20.379413 -37.253903 -28.351833    0.002023  \n",
       "128354   9.831254  10.872589  37.812440  18.337899    0.000085  \n",
       "\n",
       "[16000 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20efd382-2020-429f-a153-c68ccf79ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MLP, LGBM Stacked Ensemble: Validation Set Performance ==========\n",
      "Training accuracy: 0.959921875\n",
      "Validation accuracy: 0.9591875\n",
      "\n",
      "Training f025_score: 0.9481008502226449\n",
      "Validation f025_score: 0.9491966601592932\n",
      "\n",
      "Training f05_score: 0.9487653890013731\n",
      "Validation f05_score: 0.9491757813717243\n",
      "\n",
      "Training avg_dollars_lost_per_prediction: -2.4846875\n",
      "Validation avg_dollars_lost_per_prediction: -2.44625\n",
      "\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "scorers_dict = {\"accuracy\":make_scorer(accuracy_score), \n",
    "                \"f025_score\":make_scorer(fbeta_score, beta=0.25),\n",
    "                \"f05_score\":make_scorer(fbeta_score, beta=0.5), \n",
    "                \"avg_dollars_lost_per_prediction\":make_scorer(score_func=average_dollars_scorer_sklearn, \n",
    "                                                              greater_is_better=False)}\n",
    "\n",
    "evaluate_baseline_model(X_train=X_train_ensemble, \n",
    "                        y_train=y_train,\n",
    "                        X_val=X_val_ensemble, \n",
    "                        y_val=y_val, \n",
    "                        scorers_dict=scorers_dict,\n",
    "                        model_pipe=mlp_pipe, \n",
    "                        model_name=\"MLP, LGBM Stacked Ensemble: Validation Set Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e765c844-87c7-48e1-bde8-de348530f826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MLP, LGBM Stacked Ensemble: Test Set Performance ==========\n",
      "Training accuracy: 0.959921875\n",
      "Validation accuracy: 0.9595625\n",
      "\n",
      "Training f025_score: 0.9481008502226449\n",
      "Validation f025_score: 0.9499174766183753\n",
      "\n",
      "Training f05_score: 0.9487653890013731\n",
      "Validation f05_score: 0.9498129675810473\n",
      "\n",
      "Training avg_dollars_lost_per_prediction: -2.4846875\n",
      "Validation avg_dollars_lost_per_prediction: -2.41375\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline_model(X_train=X_train_ensemble, \n",
    "                        y_train=y_train,\n",
    "                        X_val=X_test_ensemble, \n",
    "                        y_val=y_test, \n",
    "                        model_pipe=mlp_pipe,  \n",
    "                        scorers_dict=scorers_dict,\n",
    "                        model_name=\"MLP, LGBM Stacked Ensemble: Test Set Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa3acda-214c-46f7-a454-e70064ade148",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_df = pd.DataFrame({\"true\":y_train, \n",
    "                              \"predicted\":mlp_pipe.predict(X_train_ensemble)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7f790f6-ab59-4d0e-9147-5f547b9e1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix_from_estimator(df=train_dai_df, \n",
    "#                                      target=train_dai_df['y'], \n",
    "#                                      model=mlp_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0584b-df46-47a4-a0a9-ee190430c57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d8fc415-f18c-4d02-95af-5912ef24b19c",
   "metadata": {},
   "source": [
    "## Fit MLP using LGBM as features, and scaled inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87988c4a-37ce-47e8-820f-b3f0d74287f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbacb95b-a823-4e5c-b05e-2e4d236982f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;standard_scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "              hidden_layer_sizes=(300, 200, 100), learning_rate_init=0.01,\n",
       "              max_iter=20000, random_state=7742, warm_start=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                ('standard_scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pipe_sc = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "                              (\"standard_scaler\", StandardScaler()),\n",
    "                           (\"model\", MLPClassifier(random_state=7742,\n",
    "                                                   verbose=False,\n",
    "                                                   warm_start=True,\n",
    "                                                   early_stopping=True,\n",
    "                                                   max_iter=20_000, \n",
    "                                                   alpha=1e-5, \n",
    "                                                   hidden_layer_sizes=(300,200,100), \n",
    "                                                   learning_rate_init=0.01))])\n",
    "\n",
    "mlp_pipe_sc.fit(X_train_ensemble, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8027e78-0a2a-4b8a-a324-bb48f08d164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MLP, LGBM Stacked Ensemble: Validation Set Performance ==========\n",
      "Training accuracy: 0.981859375\n",
      "Validation accuracy: 0.9736875\n",
      "\n",
      "Training f025_score: 0.9828226619830972\n",
      "Validation f025_score: 0.9757444383193027\n",
      "\n",
      "Training f05_score: 0.9810320813956233\n",
      "Validation f05_score: 0.9728865097716258\n",
      "\n",
      "Training avg_dollars_lost_per_prediction: -0.8834375\n",
      "Validation avg_dollars_lost_per_prediction: -1.25125\n",
      "\n",
      "============================================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline_model(X_train=X_train_ensemble, \n",
    "                        y_train=y_train,\n",
    "                        X_val=X_val_ensemble, \n",
    "                        y_val=y_val, \n",
    "                        scorers_dict=scorers_dict,\n",
    "                        model_pipe=mlp_pipe_sc, \n",
    "                        model_name=\"MLP, LGBM Stacked Ensemble: Validation Set Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b065c7-c33a-44ea-9610-8852a57a7a21",
   "metadata": {},
   "source": [
    "## No LGBM, No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94e94600-f375-42b2-b0a0-22e69d5c6760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;impute&#x27;, SimpleImputer()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "              hidden_layer_sizes=(300, 200, 100), learning_rate_init=0.01,\n",
       "              max_iter=20000, random_state=7742, warm_start=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('impute', SimpleImputer()),\n",
       "                ('model',\n",
       "                 MLPClassifier(alpha=1e-05, early_stopping=True,\n",
       "                               hidden_layer_sizes=(300, 200, 100),\n",
       "                               learning_rate_init=0.01, max_iter=20000,\n",
       "                               random_state=7742, warm_start=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pipe_no_ens = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"mean\")),\n",
    "                           (\"model\", MLPClassifier(random_state=7742,\n",
    "                                                   verbose=False,\n",
    "                                                   warm_start=True,\n",
    "                                                   early_stopping=True,\n",
    "                                                   max_iter=20_000, \n",
    "                                                   alpha=1e-5, \n",
    "                                                   hidden_layer_sizes=(300,200,100), \n",
    "                                                   learning_rate_init=0.01))])\n",
    "\n",
    "mlp_pipe_no_ens.fit(X_train_dai, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a6f86fd-68aa-4d25-bdcd-8a2065159c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MLP (no Scaling): Validation Set Performance ==========\n",
      "Training accuracy: 0.9725625\n",
      "Validation accuracy: 0.9681875\n",
      "\n",
      "Training f025_score: 0.9665904777640851\n",
      "Validation f025_score: 0.9643527725107526\n",
      "\n",
      "Training f05_score: 0.9663296905592087\n",
      "Validation f05_score: 0.9630059981785636\n",
      "\n",
      "Training avg_dollars_lost_per_prediction: -1.615625\n",
      "Validation avg_dollars_lost_per_prediction: -1.75125\n",
      "\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline_model(X_train=X_train_dai, \n",
    "                        y_train=y_train,\n",
    "                        X_val=X_val_dai, \n",
    "                        y_val=y_val, \n",
    "                        scorers_dict=scorers_dict,\n",
    "                        model_pipe=mlp_pipe_no_ens, \n",
    "                        model_name=\"MLP (no Scaling): Validation Set Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93b089-4da3-446d-8856-83830a2c5dd5",
   "metadata": {},
   "source": [
    "## No LGBM, With Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "606dface-45fc-4264-8f4d-01f0218aa16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MLP (with scaling): Validation Set Performance ==========\n",
      "Training accuracy: 0.98321875\n",
      "Validation accuracy: 0.9774375\n",
      "\n",
      "Training f025_score: 0.9806031659200454\n",
      "Validation f025_score: 0.977706385388908\n",
      "\n",
      "Training f05_score: 0.9801057589414733\n",
      "Validation f05_score: 0.9757711333060273\n",
      "\n",
      "Training avg_dollars_lost_per_prediction: -0.949375\n",
      "Validation avg_dollars_lost_per_prediction: -1.13125\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "mlp_pipe_sc_no_ens = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "                              (\"standard_scaler\", StandardScaler()),\n",
    "                           (\"model\", MLPClassifier(random_state=7742,\n",
    "                                                   verbose=False,\n",
    "                                                   warm_start=True,\n",
    "                                                   early_stopping=True,\n",
    "                                                   max_iter=20_000, \n",
    "                                                   alpha=1e-5, \n",
    "                                                   hidden_layer_sizes=(300,200,100), \n",
    "                                                   learning_rate_init=0.01))])\n",
    "\n",
    "mlp_pipe_sc_no_ens.fit(X_train_dai, y_train)\n",
    "\n",
    "evaluate_baseline_model(X_train=X_train_dai, \n",
    "                        y_train=y_train,\n",
    "                        X_val=X_val_dai, \n",
    "                        y_val=y_val, \n",
    "                        scorers_dict=scorers_dict,\n",
    "                        model_pipe=mlp_pipe_sc_no_ens, \n",
    "                        model_name=\"MLP (with scaling): Validation Set Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caae8f5-aab1-4944-8f67-6439667b27ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e775f-393b-44f6-ba3d-2042595e16a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a012e6-5603-4dc9-be0b-86ccdac81c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0714890-ddbc-421b-9020-77c8c7fa49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble_df = pd.DataFrame(X_train_ensemble)\n",
    "train_ensemble_df['y'] = y_train\n",
    "\n",
    "val_ensemble_df = pd.DataFrame(X_val_ensemble)\n",
    "val_ensemble_df['y'] = y_val\n",
    "\n",
    "test_ensemble_df = pd.DataFrame(X_test_ensemble)\n",
    "test_ensemble_df['y'] = y_test\n",
    "\n",
    "train_ensemble_df.to_csv(\"./train_ensemble.csv\", index=False)\n",
    "val_ensemble_df.to_csv(\"./val_ensemble.csv\", index=False)\n",
    "test_ensemble_df.to_csv(\"./test_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dfa26-22d3-42f4-ad95-0b95ec55d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone_smu]",
   "language": "python",
   "name": "conda-env-capstone_smu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
